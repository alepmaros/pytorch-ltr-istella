{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbf0a7-71b7-408e-8c3c-123cf02dffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from losses import rankNet\n",
    "\n",
    "# CUDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31074939-34c0-4b7e-92cd-de1803729c88",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee786a31-8f4f-4009-bb66-9b38ba359208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairWiseDataset(Dataset):\n",
    "    def __init__(self, root_dir=\"./datasets/istella-letor/train_parquet/*\"):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            root_dir (string): Directory with all the queries.\n",
    "        \"\"\"\n",
    "        self.queries = list()\n",
    "        for query in glob.glob(root_dir):\n",
    "            self.queries.append(query)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries) // 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        df = pd.read_parquet(glob.glob(self.queries[idx] + \"/*.parquet\")[0])\n",
    "\n",
    "        labels = torch.tensor(df[\"label\"].to_numpy().reshape(-1))\n",
    "        length_labels = labels.shape[0]\n",
    "\n",
    "        # TODO: Make 433 a variable\n",
    "        labels = F.pad(labels, (0, 433 - length_labels), \"constant\", -1)\n",
    "\n",
    "        features = torch.tensor(np.array(df[\"features.values\"].values.tolist(), dtype=np.float32))\n",
    "        features = F.pad(features, (0, 0, 0, 433 - length_labels), \"constant\", -1)\n",
    "\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094dd4c-4fa7-4ed6-96d2-841c369f850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairWiseDataset()\n",
    "train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=32, shuffle=True, prefetch_factor=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c531f-fff7-4b5d-a720-cc5c5eb06a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, labels in train_dataloader:\n",
    "    # Here, anchor, positive, and negative are batches of samples\n",
    "    print(f\"positive: {features}\\n{features.shape}\\n\\n\")\n",
    "    print(f\"negative: {labels}\\n{labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3dfb29-5e07-4f15-b51a-98b388616c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNLTR(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size= 100):\n",
    "        super(DNNLTR, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Linear(input_size, 220),\n",
    "          nn.BatchNorm1d(220),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(220, 64),\n",
    "          nn.BatchNorm1d(64),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64, 32),\n",
    "          nn.BatchNorm1d(32),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e0689-d910-4830-a0e1-f53c1e884c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 220  # Example input size\n",
    "output_size = 1  # Output size is 1 for ranking scores\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "model = DNNLTR(input_size, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee87da0-ab0e-49db-8b41-96116006c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.\n",
    "    # last_loss = 0.\n",
    "    print(epoch)\n",
    "    for i, data in enumerate(tqdm(train_dataloader)):\n",
    "        features = data[0]\n",
    "        label = data[1].float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # # Forward pass\n",
    "        output = model(features.reshape(-1, 220)).reshape(-1, 433)\n",
    "        # print(output)\n",
    "        # print(output.shape)\n",
    "        \n",
    "        # output2 = model(x2)\n",
    "    \n",
    "        # # Compute the loss\n",
    "        loss = rankNet(output, label)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    \n",
    "        # # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {(running_loss / len(train_dataloader)):.4f}\")\n",
    "    running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e7fe7-ce1d-491f-ae5e-b11fb3ce25b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
