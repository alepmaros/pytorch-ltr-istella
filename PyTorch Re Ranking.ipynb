{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbf0a7-71b7-408e-8c3c-123cf02dffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import rankNet\n",
    "from ndcg import ndcg as allRankNDCG\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31074939-34c0-4b7e-92cd-de1803729c88",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee786a31-8f4f-4009-bb66-9b38ba359208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairWiseDataset(Dataset):\n",
    "    def __init__(self, root_dir=\"./datasets/istella-letor/train_parquet/*\"):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            root_dir (string): Directory with all the queries.\n",
    "        \"\"\"\n",
    "        self.queries = list()\n",
    "        for query in glob.glob(root_dir):\n",
    "            self.queries.append(query)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        df = pd.read_parquet(glob.glob(self.queries[idx] + \"/*.parquet\")[0])\n",
    "\n",
    "        labels = torch.tensor(df[\"label\"].to_numpy().reshape(-1))\n",
    "        length_labels = labels.shape[0]\n",
    "\n",
    "        # TODO: Make 433 a variable\n",
    "        labels = F.pad(labels, (0, 433 - length_labels), \"constant\", -1)\n",
    "\n",
    "        features = torch.tensor(\n",
    "            np.array(df[\"features.values\"].values.tolist(), dtype=np.float32)\n",
    "        )\n",
    "        features = F.pad(features, (0, 0, 0, 433 - length_labels), \"constant\", -1)\n",
    "\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094dd4c-4fa7-4ed6-96d2-841c369f850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairWiseDataset()\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=8,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    prefetch_factor=10,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataset = PairWiseDataset(root_dir=\"./datasets/istella-letor/test_parquet/*\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=256,\n",
    "    prefetch_factor=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3dfb29-5e07-4f15-b51a-98b388616c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNLTR(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=[220, 128, 64, 32], dropout_rate=0.3):\n",
    "        super(DNNLTR, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(input_size, hidden_sizes[i]))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.BatchNorm1d(hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_sizes[-1], 1))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e0689-d910-4830-a0e1-f53c1e884c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 220  # Example input size\n",
    "output_size = 1  # Output size is 1 for ranking scores\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "model = DNNLTR(input_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, epoch, data_loader, optimizer, scheduler, writer):\n",
    "    running_loss = 0.0\n",
    "    ndcgs = list()\n",
    "    model.train()\n",
    "    for i, data in enumerate(tqdm(data_loader)):\n",
    "        features = data[0].to(device)\n",
    "        label = data[1].float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(features.reshape(-1, 220)).reshape(-1, 433)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = rankNet(output, label)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Avg NDCG of batch\n",
    "        ndcgs.append(allRankNDCG(output.detach(), label.detach()).mean().item())\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    avg_ndcg = np.mean(ndcgs)\n",
    "    print(\"Average Loss train: \", avg_loss)\n",
    "    writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "    writer.add_scalar(\"ndcg/train\", avg_ndcg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b716ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, epoch, data_loader, writer):\n",
    "    running_loss = 0.0\n",
    "    ndcgs = list()\n",
    "    model.eval()\n",
    "    for i, data in enumerate(tqdm(data_loader)):\n",
    "        features = data[0].to(device)\n",
    "        label = data[1].float().to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(features.reshape(-1, 220)).reshape(-1, 433)\n",
    "            \n",
    "            loss = rankNet(output, label)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Avg NDCG of batch\n",
    "            ndcgs.append(allRankNDCG(output, label).mean().item())\n",
    "\n",
    "\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    avg_ndcg = np.mean(ndcgs)\n",
    "    print(\"Average Loss test: \", avg_loss)\n",
    "    writer.add_scalar(\"Loss/test\", avg_loss, epoch)\n",
    "    writer.add_scalar(\"ndcg/test\", avg_ndcg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6beccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(40):\n",
    "    train_one_epoch(model, epoch, train_dataloader, optimizer, scheduler, writer)\n",
    "    validate(model, epoch, train_dataloader, writer)\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e7fe7-ce1d-491f-ae5e-b11fb3ce25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
