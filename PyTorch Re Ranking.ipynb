{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f2f3e-4161-425b-afb2-fafb2a300d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Links\n",
    "# Introduction to Neural Re-Ranking - https://www.youtube.com/watch?v=GSixIsI1eZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7703ed0c-7156-4534-bd89-c4fca59bb716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "51fbf0a7-71b7-408e-8c3c-123cf02dffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CUDA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "bb8864dd-0167-48e7-b2a0-828c08b07d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "def rankNet(y_pred, y_true, padded_value_indicator=-1, weight_by_diff=False, weight_by_diff_powed=False):\n",
    "    \"\"\"\n",
    "    RankNet loss introduced in \"Learning to Rank using Gradient Descent\".\n",
    "    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n",
    "    :param y_true: ground truth labels, shape [batch_size, slate_length]\n",
    "    :param weight_by_diff: flag indicating whether to weight the score differences by ground truth differences.\n",
    "    :param weight_by_diff_powed: flag indicating whether to weight the score differences by the squared ground truth differences.\n",
    "    :return: loss value, a torch.Tensor\n",
    "    \"\"\"\n",
    "    y_pred = y_pred.clone()\n",
    "    y_true = y_true.clone()\n",
    "\n",
    "    mask = y_true == padded_value_indicator\n",
    "    y_pred[mask] = float('-inf')\n",
    "    y_true[mask] = float('-inf')\n",
    "\n",
    "    # here we generate every pair of indices from the range of document length in the batch\n",
    "    document_pairs_candidates = list(product(range(y_true.shape[1]), repeat=2))\n",
    "\n",
    "    pairs_true = y_true[:, document_pairs_candidates]\n",
    "    selected_pred = y_pred[:, document_pairs_candidates]\n",
    "\n",
    "    # here we calculate the relative true relevance of every candidate pair\n",
    "    true_diffs = pairs_true[:, :, 0] - pairs_true[:, :, 1]\n",
    "    pred_diffs = selected_pred[:, :, 0] - selected_pred[:, :, 1]\n",
    "\n",
    "    # here we filter just the pairs that are 'positive' and did not involve a padded instance\n",
    "    # we can do that since in the candidate pairs we had symetric pairs so we can stick with\n",
    "    # positive ones for a simpler loss function formulation\n",
    "    the_mask = (true_diffs > 0) & (~torch.isinf(true_diffs))\n",
    "\n",
    "    pred_diffs = pred_diffs[the_mask]\n",
    "\n",
    "    weight = None\n",
    "    if weight_by_diff:\n",
    "        abs_diff = torch.abs(true_diffs)\n",
    "        weight = abs_diff[the_mask]\n",
    "    elif weight_by_diff_powed:\n",
    "        true_pow_diffs = torch.pow(pairs_true[:, :, 0], 2) - torch.pow(pairs_true[:, :, 1], 2)\n",
    "        abs_diff = torch.abs(true_pow_diffs)\n",
    "        weight = abs_diff[the_mask]\n",
    "\n",
    "    # here we 'binarize' true relevancy diffs since for a pairwise loss we just need to know\n",
    "    # whether one document is better than the other and not about the actual difference in\n",
    "    # their relevancy levels\n",
    "    true_diffs = (true_diffs > 0).type(torch.float32)\n",
    "    true_diffs = true_diffs[the_mask]\n",
    "\n",
    "    return BCEWithLogitsLoss(weight=weight)(pred_diffs, true_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31074939-34c0-4b7e-92cd-de1803729c88",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ee786a31-8f4f-4009-bb66-9b38ba359208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairWiseDataset(Dataset):\n",
    "    def __init__(self, root_dir=\"./datasets/istella-letor/train_parquet/*\"):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            root_dir (string): Directory with all the queries.\n",
    "        \"\"\"\n",
    "        self.queries = list()\n",
    "        for query in glob.glob(root_dir):\n",
    "            self.queries.append(query)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries) // 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        df = pd.read_parquet(glob.glob(self.queries[idx] + \"/*.parquet\")[0])\n",
    "\n",
    "        labels = torch.tensor(df[\"label\"].to_numpy().reshape(-1))\n",
    "        length_labels = labels.shape[0]\n",
    "        # TODO: Make 433 a variable\n",
    "        labels = F.pad(labels, (0, 433 - length_labels), \"constant\", -1)\n",
    "\n",
    "        features = torch.tensor(np.array(df[\"features.values\"].values.tolist(), dtype=np.float32))\n",
    "        features = F.pad(features, (0, 0, 0, 433 - length_labels), \"constant\", -1)\n",
    "\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a094dd4c-4fa7-4ed6-96d2-841c369f850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairWiseDataset()\n",
    "train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3d6c531f-fff7-4b5d-a720-cc5c5eb06a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: tensor([[[ 0.0000e+00,  1.0000e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.0130e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.0160e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.0230e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.0400e+03,  2.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.2600e+02,  2.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.0600e+02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.0730e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000e+00,  1.1010e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.1090e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.1266e+04,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.0400e+02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.0710e+03,  2.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 9.5647e+04,  3.8600e+02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 9.5647e+04,  7.9600e+02,  2.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 9.5813e+06,  1.8218e+04,  2.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.4864e+04,  2.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.7956e+04,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  2.0049e+05,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00]]])\n",
      "torch.Size([32, 433, 220])\n",
      "\n",
      "\n",
      "negative: tensor([[ 0,  0,  0,  ..., -1, -1, -1],\n",
      "        [ 0,  0,  0,  ..., -1, -1, -1],\n",
      "        [ 0,  0,  0,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 0,  0,  0,  ..., -1, -1, -1],\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0,  0,  ..., -1, -1, -1]], dtype=torch.int32)\n",
      "torch.Size([32, 433])\n"
     ]
    }
   ],
   "source": [
    "for features, labels in train_dataloader:\n",
    "    # Here, anchor, positive, and negative are batches of samples\n",
    "    print(f\"positive: {features}\\n{features.shape}\\n\\n\")\n",
    "    print(f\"negative: {labels}\\n{labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5d3dfb29-5e07-4f15-b51a-98b388616c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNLTR(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size= 100):\n",
    "        super(DNNLTR, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1ad75c2d-49e8-46b9-a2c5-9b6d5bc8facf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([220, 13856])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.reshape(220, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ac42085f-a52e-4010-a52d-38ba876f434a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.7830e+03],\n",
       "        [7.6529e+03],\n",
       "        [7.7664e+03],\n",
       "        ...,\n",
       "        [3.1298e-01],\n",
       "        [3.1298e-01],\n",
       "        [3.1298e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(features.reshape(-1, 220))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ead2af0f-3c13-451a-b490-c96ceb8e1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 220  # Example input size\n",
    "output_size = 1  # Output size is 1 for ranking scores\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "model = DNNLTR(input_size, output_size)\n",
    "# criterion = nn.MarginRankingLoss(margin=1.0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7ee87da0-ab0e-49db-8b41-96116006c2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 363/363 [01:27<00:00,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    print(epoch)\n",
    "    for i, data in enumerate(tqdm(train_dataloader)):\n",
    "        features = data[0]\n",
    "        label = data[1].float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # # Forward pass\n",
    "        output = model(features).squeeze(-1)\n",
    "        # print(output)\n",
    "        # print(output.shape)\n",
    "        \n",
    "        # output2 = model(x2)\n",
    "    \n",
    "        # # Compute the loss\n",
    "        loss = rankNet(output, label)\n",
    "        # print(loss)\n",
    "        # break\n",
    "    \n",
    "        # # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8e497f21-2e50-442c-85cf-03f11b1a7171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.1524e+02, -8.3098e+02, -9.2494e+02, -8.4188e+02, -8.0577e+02,\n",
       "         -1.1002e+03, -8.3113e+02, -8.1476e+02, -9.4506e+02, -7.7314e+02,\n",
       "         -2.4954e+03, -9.3460e+02, -8.1591e+02, -8.0336e+02, -2.9345e+03,\n",
       "         -1.5114e+03, -9.4529e+02, -1.1154e+03, -8.9665e+02, -8.8047e+02,\n",
       "         -8.3442e+02, -8.9205e+02, -1.8085e+03, -8.1146e+02, -9.6781e+02,\n",
       "         -8.8013e+02, -8.3312e+02, -8.9791e+02, -8.3417e+02, -9.0948e+02,\n",
       "         -2.3312e+03, -8.9629e+02, -1.3082e+03, -8.4684e+02, -8.2488e+02,\n",
       "         -8.3881e+02, -1.5201e+03, -7.9262e+02, -7.9045e+02, -8.5237e+02,\n",
       "         -8.3793e+02, -7.8648e+02, -1.2979e+03, -7.8789e+02, -8.0407e+02,\n",
       "         -8.1880e+02, -8.0146e+02, -7.8685e+02, -8.3741e+02, -8.3371e+02,\n",
       "         -9.3610e+02, -8.0021e+02, -1.1307e+03, -8.1219e+02, -8.0421e+02,\n",
       "         -8.0168e+02, -8.8506e+02, -8.5868e+02, -8.2921e+02, -1.6071e+03,\n",
       "         -1.1881e+03, -7.8677e+02, -7.9797e+02, -7.8644e+02, -1.4684e+03,\n",
       "         -1.0041e+03, -8.3388e+02, -1.4448e+02,  1.7879e+05,  1.7997e+05,\n",
       "          1.7995e+05,  1.8089e+05,  1.8178e+05,  1.8290e+05,  1.8303e+05,\n",
       "          1.8540e+05,  1.8613e+05,  1.8613e+05,  1.9255e+04, -4.9853e+01,\n",
       "         -4.9853e+01,  5.8254e+01,  1.9730e+04,  1.9797e+04,  1.9791e+04,\n",
       "          1.9792e+04,  1.9788e+04,  1.9788e+04,  1.9794e+04,  1.9782e+04,\n",
       "          1.9768e+04,  1.9723e+04,  1.9686e+04,  1.9813e+04,  1.9816e+04,\n",
       "          1.9811e+04,  1.9813e+04,  1.9757e+04,  1.9168e+05,  1.9293e+05,\n",
       "          1.9219e+05,  1.9880e+05,  1.9845e+05,  1.9847e+05,  1.9844e+05,\n",
       "          1.9840e+05,  1.9845e+05,  1.9840e+05,  1.9839e+05,  1.9842e+05,\n",
       "          1.9849e+05,  1.9841e+05,  1.9848e+05,  1.9838e+05,  1.9833e+05,\n",
       "          1.9866e+05,  1.9869e+05,  2.1089e+04,  2.0711e+04,  2.0885e+04,\n",
       "         -7.7822e+00,  2.0260e+05,  2.1801e+04,  2.1025e+04,  2.0505e+05,\n",
       "          2.0488e+05,  2.5141e+02,  2.6166e+02,  2.0967e+05,  2.2733e+04,\n",
       "          2.2733e+04,  2.1362e+05,  2.1350e+05,  2.2131e+04,  2.2122e+04,\n",
       "          2.2107e+04,  1.9913e+02,  2.4261e+02,  1.6632e+02,  2.0269e+02,\n",
       "          1.9081e+02,  1.9277e+02,  2.2427e+04,  2.2429e+04,  2.2432e+04,\n",
       "          2.2423e+04,  2.2412e+04,  2.2407e+04,  2.2397e+04,  2.2415e+04,\n",
       "          2.2308e+04,  2.2298e+04,  2.7558e+02,  2.2714e+04,  2.1890e+05,\n",
       "          2.2280e+05,  2.2582e+05,  2.4350e+04,  2.2718e+05, -6.4235e+02,\n",
       "         -5.3051e+03, -1.4071e+03, -1.2120e+03,  2.4676e+04,  3.4475e+02,\n",
       "          2.3677e+05, -2.4625e+03,  2.4934e+05,  2.7121e+04,  2.6640e+04,\n",
       "          2.7356e+04,  7.0323e+02,  5.8704e+02,  7.5443e+02,  7.5824e+02,\n",
       "          7.5890e+02,  7.3767e+02,  7.7221e+02,  6.5100e+02,  7.2050e+02,\n",
       "          7.4769e+02,  2.5682e+05,  2.8135e+04,  2.9017e+04,  2.9554e+04,\n",
       "          5.6920e+02,  2.8289e+05,  2.8654e+05,  2.8974e+05,  1.1176e+03,\n",
       "          2.9445e+05,  1.0230e+03,  3.2608e+04,  3.2667e+04,  2.7254e+04,\n",
       "          3.2952e+04,  3.4887e+04, -8.1750e+02, -8.2565e+02, -8.3715e+02,\n",
       "          1.4529e+03,  1.4438e+03,  3.5953e+04,  3.5956e+04,  3.5936e+04,\n",
       "          3.3406e+05,  3.6987e+04,  3.6943e+04,  3.6023e+04,  3.5321e+05,\n",
       "          1.8292e+03,  1.7180e+03,  1.7938e+03,  1.7959e+03,  1.8116e+03,\n",
       "          3.9123e+04,  3.8842e+04,  1.9437e+03,  1.8984e+03,  2.0475e+03,\n",
       "          3.7713e+05,  2.1274e+03,  4.2992e+04,  4.2871e+04,  4.3101e+04,\n",
       "          4.2864e+04,  4.2482e+04,  4.0020e+05,  3.9943e+05,  2.4861e+03,\n",
       "          4.0294e+05,  4.3462e+04,  4.0606e+05,  4.0755e+05,  4.0755e+05,\n",
       "          4.0756e+05,  4.0755e+05,  4.0742e+05,  4.0937e+05,  4.1457e+05,\n",
       "          4.1553e+05,  4.1537e+05,  4.1635e+05,  4.3850e+04,  2.2808e+03,\n",
       "          2.8450e+03,  4.7298e+04,  4.2719e+05,  4.4925e+04,  4.3239e+05,\n",
       "          4.3249e+05,  2.8463e+03,  4.3933e+05,  4.3959e+05,  4.4029e+05,\n",
       "          2.7288e+03,  4.8641e+04,  4.7554e+04,  2.9040e+03,  3.0749e+03,\n",
       "          4.8048e+04,  3.3895e+03,  3.4010e+03,  4.9689e+04,  3.6800e+03,\n",
       "          3.6747e+03,  3.3329e+03,  5.2020e+04,  3.7001e+03,  3.6476e+03,\n",
       "          3.6983e+03,  3.6989e+03,  3.6981e+03,  3.6914e+03,  3.6960e+03,\n",
       "          3.6989e+03,  3.6993e+03,  3.7896e+03,  5.5335e+04,  3.7912e+03,\n",
       "          3.7701e+03,  3.8771e+03, -1.1963e+03, -8.1182e+02, -7.6980e+02,\n",
       "         -1.3299e+03, -1.0234e+03, -7.8993e+02, -1.2033e+03, -1.1589e+03,\n",
       "         -8.5913e+02,  3.9582e+03,  5.8362e+04,  6.0710e+04,  6.0612e+04,\n",
       "          5.9294e+04,  5.9541e+04,  5.9409e+04,  6.0371e+03,  6.2206e+04,\n",
       "          6.1332e+04,  6.5968e+04, -8.2025e+02,  4.5844e+03,  4.5561e+03,\n",
       "          6.6099e+04, -8.3803e+02,  4.5732e+03,  6.6096e+04,  4.5563e+03,\n",
       "         -8.0599e+02, -8.1364e+02, -8.9537e+02, -1.4763e+03, -8.5831e+02,\n",
       "          4.3514e+03,  3.4730e+03, -9.2047e+02,  7.5921e+04,  5.1855e+03,\n",
       "          5.0677e+03,  7.9695e+04,  7.8912e+04,  7.8455e+04, -6.8039e+02,\n",
       "          8.3003e+04,  5.2568e+03,  8.0295e+04, -1.5783e+03,  5.1860e+03,\n",
       "          8.4088e+04,  5.3912e+03,  5.3590e+03,  5.3888e+03, -6.7525e+02,\n",
       "         -7.8257e+02, -8.3981e+02, -7.1891e+02, -7.1616e+02, -6.8649e+02,\n",
       "          5.1040e+03,  5.4810e+03,  5.2486e+03,  5.8140e+03, -3.6966e+02,\n",
       "         -7.1349e+02, -7.1044e+02,  6.5245e+03,  6.2804e+03,  7.1058e+03,\n",
       "          7.1923e+03,  9.6870e+04,  9.7750e+04,  7.1585e+03,  1.0123e+05,\n",
       "          7.8161e+03,  1.0228e+05,  1.0319e+05,  1.0344e+05,  8.0763e+03,\n",
       "          8.0280e+03, -9.2807e+02, -6.6219e+02,  1.1011e+05,  9.1216e+03,\n",
       "          9.1450e+03,  9.1787e+03,  9.1656e+03,  9.1825e+03,  9.0642e+03,\n",
       "          9.0411e+03,  8.8732e+03,  8.8603e+03, -6.0909e+02,  1.1451e+05,\n",
       "         -9.4263e+02, -2.7075e+03, -2.8952e+03, -3.1765e+03,  1.1775e+05,\n",
       "          1.2256e+05,  1.0748e+04, -8.7324e+02,  1.2528e+05,  1.2528e+05,\n",
       "          1.0814e+04,  1.0807e+04,  1.1770e+04,  1.1709e+04,  1.1757e+04,\n",
       "          1.1415e+04,  1.2156e+04,  1.3226e+05,  1.3055e+05, -6.7852e+02,\n",
       "         -1.0154e+03,  1.2278e+04, -3.8044e+02,  1.3782e+04, -4.1099e+02,\n",
       "          1.4628e+05,  1.4823e+04,  1.4837e+04, -8.0401e+02,  1.4857e+05,\n",
       "          1.4600e+04, -4.7443e+02, -4.2202e+02, -2.2123e+03, -3.2428e+02,\n",
       "         -1.0957e+03, -3.8100e+02, -3.2775e+02,  1.5989e+05,  1.5992e+04,\n",
       "         -1.5712e+02,  1.6874e+05,  1.6907e+05, -1.5921e+02, -2.5172e+02,\n",
       "          1.5662e-01,  1.5662e-01,  1.5662e-01,  1.5662e-01,  1.5662e-01,\n",
       "          1.5662e-01,  1.5662e-01,  1.5662e-01,  1.5662e-01,  1.5662e-01,\n",
       "          1.5662e-01,  1.5662e-01,  1.5662e-01],\n",
       "        [-8.2396e+02, -8.3280e+02, -8.6958e+02, -8.9930e+02, -7.8991e+02,\n",
       "         -7.8398e+02, -8.2816e+02, -7.7659e+02, -8.6784e+02, -8.0097e+02,\n",
       "         -7.9765e+02, -8.4511e+02, -8.2231e+02, -8.3818e+02, -7.8388e+02,\n",
       "         -8.7691e+02, -7.9924e+02, -8.7961e+02, -8.2733e+02, -8.0464e+02,\n",
       "         -8.6292e+02, -8.2623e+02, -8.1219e+02, -8.6282e+02, -8.5871e+02,\n",
       "         -8.8357e+02, -9.0114e+02, -8.7152e+02, -8.3469e+02, -8.4020e+02,\n",
       "         -8.2150e+02, -8.2708e+02, -7.8154e+02, -8.5336e+02, -8.3176e+02,\n",
       "         -8.5796e+02, -8.7730e+02, -8.6129e+02, -8.8690e+02, -8.0558e+02,\n",
       "         -8.3250e+02, -9.0706e+02, -1.0718e+03, -9.0343e+02, -8.0779e+02,\n",
       "         -8.4406e+02, -7.8036e+02, -8.4093e+02, -8.5073e+02, -9.0220e+02,\n",
       "         -1.6096e+03, -9.2566e+02, -7.9514e+02, -9.7152e+02, -8.6577e+02,\n",
       "         -9.6353e+02, -8.6784e+02, -1.1669e+03, -7.9044e+02, -1.1743e+03,\n",
       "         -7.7488e+02, -8.1692e+02, -1.1780e+03, -7.9113e+02, -8.5219e+02,\n",
       "         -9.3389e+02, -1.7086e+03, -1.0096e+03, -8.4358e+02, -9.1638e+02,\n",
       "         -8.5587e+02, -1.2273e+03, -9.4102e+02, -8.5752e+02, -1.2607e+03,\n",
       "         -8.5692e+02, -7.8782e+02, -8.6493e+02, -8.5778e+02, -7.8746e+02,\n",
       "         -8.2650e+02, -8.8131e+02, -7.9742e+02, -7.9674e+02, -8.6726e+02,\n",
       "         -7.8853e+02, -7.7932e+02, -9.5891e+02, -8.6861e+02, -7.7936e+02,\n",
       "         -8.2038e+02, -7.7374e+02, -8.0111e+02, -7.8584e+02, -8.4422e+02,\n",
       "         -7.8945e+02, -7.7574e+02, -8.5864e+02, -1.1273e+03, -7.6967e+02,\n",
       "         -8.2585e+02, -7.8347e+02, -1.0596e+03, -7.8592e+02, -7.8494e+02,\n",
       "         -7.9950e+02, -7.8410e+02, -7.8407e+02, -9.8098e+02, -7.7636e+02,\n",
       "         -8.1848e+02, -7.7615e+02, -7.8834e+02, -7.7542e+02, -7.8197e+02,\n",
       "         -7.8239e+02, -9.6171e+02, -1.3664e+03, -7.7738e+02, -8.0921e+02,\n",
       "         -1.0756e+03, -7.7666e+02, -7.7166e+02, -7.6988e+02, -7.9711e+02,\n",
       "         -8.6227e+02, -7.9753e+02, -8.4735e+02, -7.8037e+02, -7.7374e+02,\n",
       "         -7.6779e+02, -8.4384e+02, -7.7836e+02, -8.2447e+02, -7.9049e+02,\n",
       "         -8.1623e+02, -8.0875e+02, -1.1052e+03, -1.0988e+03, -7.9633e+02,\n",
       "         -8.0272e+02, -8.2532e+02, -7.9844e+02, -8.0618e+02, -8.6601e+02,\n",
       "         -8.1364e+02, -1.1931e+03, -7.8677e+02, -8.5456e+02, -8.5323e+02,\n",
       "         -8.7068e+02, -8.7311e+02, -8.4018e+02, -8.3803e+02, -8.6308e+02,\n",
       "         -7.9958e+02, -8.0748e+02, -8.6831e+02, -8.1372e+02, -8.3124e+02,\n",
       "         -8.3567e+02, -7.8847e+02, -8.1680e+02, -8.0237e+02, -1.4241e+03,\n",
       "         -8.4166e+02, -8.4790e+02, -1.2875e+03, -8.0815e+02, -7.8592e+02,\n",
       "         -8.6908e+02, -9.1608e+02, -9.1158e+02,  1.8190e+04,  1.8498e+04,\n",
       "          1.8763e+05,  1.9072e+04, -7.5286e+02,  1.9181e+04, -2.3849e+03,\n",
       "          1.9793e+04,  3.7667e+00,  6.1690e+01,  2.0284e+01,  2.1517e+04,\n",
       "          2.0471e+05,  1.4540e+01,  2.1050e+04,  2.2906e+04,  2.2810e+04,\n",
       "          2.1586e+04, -8.6823e+02, -9.9197e+02, -8.5542e+02, -8.4850e+02,\n",
       "         -8.2903e+02,  3.2589e+02,  1.3603e+03,  2.3114e+05,  3.4328e+02,\n",
       "          2.4132e+04,  2.3834e+05,  3.5048e+02, -8.6185e+02,  2.5271e+05,\n",
       "          2.5283e+05,  2.6405e+04, -8.8703e+02, -9.8628e+02,  6.4285e+02,\n",
       "          6.0316e+02,  6.0278e+02,  7.2795e+02,  2.8185e+04, -8.7148e+02,\n",
       "          8.0067e+02, -9.4609e+02,  2.8709e+04,  2.7902e+05,  2.8906e+04,\n",
       "          9.4151e+02,  2.8462e+05,  2.9526e+04, -9.1610e+02,  1.0413e+03,\n",
       "          3.0390e+04,  3.0656e+04,  3.0862e+04,  3.0869e+04,  3.0852e+04,\n",
       "          3.1061e+04,  3.1876e+04,  3.0677e+05,  3.0744e+05,  3.2314e+04,\n",
       "         -8.9265e+02,  1.3249e+03,  3.5942e+04,  3.3678e+04,  3.2523e+05,\n",
       "          3.2613e+05,  3.4381e+04, -8.8945e+02, -9.1322e+02,  1.4085e+03,\n",
       "          3.3305e+05,  3.3553e+05,  1.3936e+03,  3.3758e+05,  3.3759e+05,\n",
       "          3.3930e+05,  3.5487e+04,  1.5557e+03,  1.5452e+03,  1.5125e+03,\n",
       "          1.5535e+03,  3.7111e+04,  3.7534e+04,  3.8898e+04,  3.8522e+04,\n",
       "          3.8505e+04, -8.4766e+02,  3.8954e+04, -7.8604e+02,  3.9035e+04,\n",
       "          3.9574e+04, -9.1098e+02,  4.1344e+04,  4.1348e+04,  4.1341e+04,\n",
       "          4.1402e+04,  3.9810e+05,  4.0212e+05,  4.0184e+05,  4.0220e+05,\n",
       "          2.1096e+03, -8.2544e+02, -8.9894e+02, -6.3590e+02,  2.3337e+03,\n",
       "          4.2545e+05,  2.4640e+03,  2.7554e+03,  4.7137e+04,  2.8039e+03,\n",
       "          4.5674e+05,  4.5799e+05, -8.4234e+02, -8.0027e+02, -1.1598e+03,\n",
       "         -8.6703e+02,  4.7153e+05,  3.0729e+03,  4.9568e+04, -8.4936e+02,\n",
       "          5.1638e+04,  5.4379e+04, -8.3793e+02,  3.7313e+03,  3.8206e+03,\n",
       "         -7.8835e+02,  5.8197e+04, -7.3072e+02, -7.7894e+02,  6.0910e+04,\n",
       "          6.1705e+04,  6.2106e+04, -8.6484e+02,  6.4112e+04,  6.5110e+04,\n",
       "          4.5777e+03, -8.6185e+02, -8.3827e+02, -8.8119e+02,  4.6591e+03,\n",
       "          6.9807e+04, -7.9865e+02,  4.9055e+03, -9.0844e+02,  7.2440e+04,\n",
       "          4.7495e+03,  4.7407e+03, -8.9734e+02, -8.4236e+02,  4.8130e+03,\n",
       "          7.6611e+04,  4.9780e+03,  4.8484e+03,  8.0709e+04,  5.1999e+03,\n",
       "          5.2832e+03, -4.7956e+01,  8.4242e+04,  5.3568e+03, -7.7192e+02,\n",
       "         -1.8732e+02,  5.4280e+03,  8.9705e+04,  6.0802e+03, -7.8778e+02,\n",
       "         -8.7521e+02,  6.2206e+03,  5.7863e+03,  9.5330e+04,  9.6124e+04,\n",
       "          6.1518e+03,  6.8160e+03,  6.3669e+03,  6.2502e+03,  6.2830e+03,\n",
       "          6.3199e+03,  6.2607e+03,  6.2659e+03,  6.2742e+03,  9.9474e+04,\n",
       "          4.4522e+02,  1.0183e+05,  1.0190e+05, -9.4691e+02,  6.9024e+03,\n",
       "          7.6499e+03, -1.6885e+03, -1.6788e+03, -1.8562e+03, -1.0324e+03,\n",
       "         -1.0802e+03,  7.9814e+03,  7.9912e+03,  7.7179e+03,  7.7158e+03,\n",
       "         -8.6798e+02,  8.8546e+03,  1.0956e+05,  1.1069e+05,  1.1069e+05,\n",
       "          1.1069e+05,  8.4662e+03,  1.1456e+05,  9.3233e+03,  9.3525e+03,\n",
       "          9.8620e+03,  9.1105e+03,  1.0035e+04,  1.2127e+05, -7.3309e+02,\n",
       "          1.2540e+05, -5.9215e+02, -7.9557e+02, -8.8982e+02,  1.0419e+04,\n",
       "          1.1159e+04,  1.1161e+04,  1.3166e+05, -8.7085e+02,  1.1607e+04,\n",
       "          1.1424e+04,  1.3335e+05,  1.3384e+05,  1.1909e+04, -4.5456e+02,\n",
       "          1.2575e+04, -8.6969e+02,  1.2329e+04, -5.7329e+02, -4.4837e+02,\n",
       "         -4.9985e+02, -4.2683e+02, -8.5797e+02, -9.4495e+02,  1.4402e+05,\n",
       "          1.4402e+05,  1.3619e+04,  1.3804e+04, -1.4370e+03,  1.3777e+04,\n",
       "          1.4770e+05, -5.0236e+02, -8.5150e+02,  1.4266e+04,  1.4929e+05,\n",
       "          1.4296e+04,  1.5030e+05,  1.4587e+04, -2.1880e+01,  1.1736e+03,\n",
       "          1.1361e+03,  1.1871e+03,  1.5944e+04,  1.6887e+04,  1.6482e+04,\n",
       "          1.6476e+04,  1.6719e+05, -2.2174e+02]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ad1021a6-0dd3-42a6-90b0-11373afdc588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = torch.randn(32, input_size)\n",
    "# x2 = torch.randn(32, input_size)\n",
    "\n",
    "# target = torch.ones(32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "07de3dee-bff8-43d6-a179-58f1733a6f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26776492-a6a1-4aeb-964b-91214a81c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6f07e-31d8-4d3b-b40f-43dac0a1cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output1 = model(x1)\n",
    "    output2 = model(x2)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(output1, output2, target)\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e7fe7-ce1d-491f-ae5e-b11fb3ce25b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
