{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fbf0a7-71b7-408e-8c3c-123cf02dffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import rankNet\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31074939-34c0-4b7e-92cd-de1803729c88",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee786a31-8f4f-4009-bb66-9b38ba359208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairWiseDataset(Dataset):\n",
    "    def __init__(self, root_dir=\"./datasets/istella-letor/train_parquet/*\"):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            root_dir (string): Directory with all the queries.\n",
    "        \"\"\"\n",
    "        self.queries = list()\n",
    "        for query in glob.glob(root_dir):\n",
    "            self.queries.append(query)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        df = pd.read_parquet(glob.glob(self.queries[idx] + \"/*.parquet\")[0])\n",
    "\n",
    "        labels = torch.tensor(df[\"label\"].to_numpy().reshape(-1))\n",
    "        length_labels = labels.shape[0]\n",
    "\n",
    "        # TODO: Make 433 a variable\n",
    "        labels = F.pad(labels, (0, 433 - length_labels), \"constant\", -1)\n",
    "\n",
    "        features = torch.tensor(\n",
    "            np.array(df[\"features.values\"].values.tolist(), dtype=np.float32)\n",
    "        )\n",
    "        features = F.pad(features, (0, 0, 0, 433 - length_labels), \"constant\", -1)\n",
    "\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a094dd4c-4fa7-4ed6-96d2-841c369f850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairWiseDataset()\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=8,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    prefetch_factor=10,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataset = PairWiseDataset(root_dir=\"./datasets/istella-letor/test_parquet/*\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=256,\n",
    "    prefetch_factor=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6c531f-fff7-4b5d-a720-cc5c5eb06a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for features, labels in train_dataloader:\n",
    "#     # Here, anchor, positive, and negative are batches of samples\n",
    "#     print(f\"positive: {features}\\n{features.shape}\\n\\n\")\n",
    "#     print(f\"negative: {labels}\\n{labels.shape}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3dfb29-5e07-4f15-b51a-98b388616c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNLTR(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=[220, 128, 64, 32], dropout_rate=0.3):\n",
    "        super(DNNLTR, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(input_size, hidden_sizes[i]))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.BatchNorm1d(hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_sizes[-1], 1))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd6e0689-d910-4830-a0e1-f53c1e884c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 220  # Example input size\n",
    "output_size = 1  # Output size is 1 for ranking scores\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "model = DNNLTR(input_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "332f6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c75b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5983cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, epoch, data_loader, optimizer, scheduler, writer):\n",
    "    running_loss = 0.0\n",
    "    ndcgs = list()\n",
    "    model.train()\n",
    "    for i, data in enumerate(tqdm(data_loader)):\n",
    "        features = data[0].to(device)\n",
    "        label = data[1].float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # # Forward pass\n",
    "        output = model(features.reshape(-1, 220)).reshape(-1, 433)\n",
    "        # print(output)\n",
    "        # print(output.shape)\n",
    "\n",
    "        # output2 = model(x2)\n",
    "\n",
    "        # # Compute the loss\n",
    "        loss = rankNet(output, label)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        for true, pred in zip(label.to(\"cpu\"), output.to(\"cpu\")):\n",
    "            ndcgs.append(\n",
    "                ndcg_score([true[true != -1].float().detach().numpy()], [pred[true != -1].float().detach().numpy()])\n",
    "            )\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    avg_ndcg = np.mean(ndcgs)\n",
    "    print(\"Average Loss train: \", avg_loss)\n",
    "    writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "    writer.add_scalar(\"ndcg/train\", avg_ndcg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b716ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, epoch, data_loader, writer):\n",
    "    running_loss = 0.0\n",
    "    ndcgs = list()\n",
    "    model.eval()\n",
    "    for i, data in enumerate(tqdm(data_loader)):\n",
    "        features = data[0].to(device)\n",
    "        label = data[1].float().to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(features.reshape(-1, 220)).reshape(-1, 433)\n",
    "            \n",
    "            loss = rankNet(output, label)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            for true, pred in zip(label.to(\"cpu\"), output.to(\"cpu\")):\n",
    "                ndcgs.append(\n",
    "                    ndcg_score([true[true != -1].float().numpy()], [pred[true != -1].float().numpy()])\n",
    "                )\n",
    "\n",
    "\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    avg_ndcg = np.mean(ndcgs)\n",
    "    print(\"Average Loss test: \", avg_loss)\n",
    "    writer.add_scalar(\"Loss/test\", avg_loss, epoch)\n",
    "    writer.add_scalar(\"ndcg/test\", avg_ndcg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6beccfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 635/726 [02:18<00:19,  4.59it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Computing NDCG is only meaningful when there is more than 1 document. Got 1 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     validate(model, epoch, train_dataloader, writer)\n\u001b[1;32m      5\u001b[0m writer\u001b[38;5;241m.\u001b[39mflush()\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, epoch, data_loader, optimizer, scheduler, writer)\u001b[0m\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m true, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(label\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m), output\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     27\u001b[0m         ndcgs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 28\u001b[0m             \u001b[43mndcg_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m         )\n\u001b[1;32m     31\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/pytorch-playground-KmN_kDag-py3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/pytorch-playground-KmN_kDag-py3.10/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1871\u001b[0m, in \u001b[0;36mndcg_score\u001b[0;34m(y_true, y_score, k, sample_weight, ignore_ties)\u001b[0m\n\u001b[1;32m   1869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndcg_score should not be used on negative y_true values.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1871\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing NDCG is only meaningful when there is more than 1 document. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1873\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1874\u001b[0m     )\n\u001b[1;32m   1875\u001b[0m _check_dcg_target_type(y_true)\n\u001b[1;32m   1876\u001b[0m gain \u001b[38;5;241m=\u001b[39m _ndcg_sample_scores(y_true, y_score, k\u001b[38;5;241m=\u001b[39mk, ignore_ties\u001b[38;5;241m=\u001b[39mignore_ties)\n",
      "\u001b[0;31mValueError\u001b[0m: Computing NDCG is only meaningful when there is more than 1 document. Got 1 instead."
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train_one_epoch(model, epoch, train_dataloader, optimizer, scheduler, writer)\n",
    "    validate(model, epoch, train_dataloader, writer)\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dfb153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true[true != -1].float().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ndcgs = list()\n",
    "# for true, pred in zip(label, output):\n",
    "#     ndcgs.append(ndcg_score([true[true != -1].float().numpy()], [pred[true != -1].float().numpy()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5435e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_2 = label.clone()\n",
    "# output_2 = output.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad5f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_2[label == -1] = 0\n",
    "# output_2[label == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndcg_score(label_2, output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ndcg import ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndcg(label, output).reshape(-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d34aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true[true != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee87da0-ab0e-49db-8b41-96116006c2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [01:16<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss train:  0.3706666540672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 35/363 [00:10<01:40,  3.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      2\u001b[0m     train_one_epoch(model, epoch, train_dataloader, optimizer, scheduler, writer)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m writer\u001b[38;5;241m.\u001b[39mflush()\n",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, epoch, data_loader, writer)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      9\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(features\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m220\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m433\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mrankNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# for true, pred in zip(label, output):\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#     ndcgs.append(\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#         ndcg_score([true[true != -1].float().numpy()], [pred[true != -1].float().numpy()])\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#     )\u001b[39;00m\n",
      "File \u001b[0;32m~/pytorch-playground/losses.py:36\u001b[0m, in \u001b[0;36mrankNet\u001b[0;34m(y_pred, y_true, padded_value_indicator, weight_by_diff, weight_by_diff_powed)\u001b[0m\n\u001b[1;32m     31\u001b[0m pred_diffs \u001b[38;5;241m=\u001b[39m selected_pred[:, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m selected_pred[:, :, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# here we filter just the pairs that are 'positive' and did not involve a padded instance\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# we can do that since in the candidate pairs we had symetric pairs so we can stick with\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# positive ones for a simpler loss function formulation\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m the_mask \u001b[38;5;241m=\u001b[39m (true_diffs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m~\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_diffs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     38\u001b[0m pred_diffs \u001b[38;5;241m=\u001b[39m pred_diffs[the_mask]\n\u001b[1;32m     40\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e7fe7-ce1d-491f-ae5e-b11fb3ce25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
